---
k3s_version: v1.30.2+k3s2
# this is the user that has ssh access to these machines
ansible_user: ansible
systemd_dir: /etc/systemd/system

# Hardening
harden_k3s_nodes: true

podsec:
  enforce: restricted
  audit: restricted
  warn: restricted

# Set your timezone
system_timezone: Europe/Amsterdam

#### Networking ####
## Cilium

## Controlplane Loadbalancer
kube_vip_arp: true
kube_vip_bgp: false
kube_vip_bgp_routerid: "127.0.0.1"  # Defines the router ID for the BGP server
kube_vip_bgp_as: "64513"  # Defines the AS for the BGP server
kube_vip_bgp_peeraddress: "192.168.30.1"  # Defines the address for the BGP peer
kube_vip_bgp_peeras: "64512"  # Defines the AS for the BGP peer

# apiserver_endpoint VIP
apiserver_endpoint: 10.10.10.5

# k3s_token is required  masters can talk together securely
# this token should be alpha numeric only
k3s_token: ChangeMe

# The IP on which the node is reachable in the cluster.
# Here, a sensible default is provided, you can still override
# it for each of your hosts, though.
k3s_cni_iface: eth0
k3s_node_ip: "{{ ansible_facts[k3s_cni_iface]['ipv4']['address'] }}"

# Do not use this in production!
cilium_pol_auditonly: true


### Cert-manager ###
cm_acme_email: j.luchtenberg@protonmail.com
cm_cf_token: 2w1XgNkbkqu3xLlDVT5utBbgQ6-boS-WjBNwZi0y
cm_domain: sprinthub.nl

# Disable the taint manually by setting: k3s_master_taint = false
k3s_master_taint: "{{ true if groups['node'] | default([]) | length >= 1 else false }}"

# these arguments are recommended for servers as well as agents:
extra_args: >-
  --node-ip={{ k3s_node_ip }}
  --protect-kernel-defaults

# change these to your liking, the only required are: --disable servicelb, --tls-san {{ apiserver_endpoint }}
# the contents of the if block is also required if using calico or cilium
extra_server_args: >-
  {{ extra_args }}
  {{ '--node-taint node-role.kubernetes.io/control-plane:NoSchedule' if k3s_master_taint else '' }}
  --flannel-backend=none
  --disable-network-policy
  --cluster-cidr={{ cilium_cluster_cidr | default('10.52.0.0/16') }}
  --tls-san {{ apiserver_endpoint }}
  --disable servicelb
  --disable traefik
  --disable local-storage
  --kube-apiserver-arg="admission-control-config-file=/var/lib/rancher/k3s/server/psa.yaml"
  --kube-controller-manager-arg="allocate-node-cidrs"
  --secrets-encryption

extra_agent_args: >-
  {{ extra_args }}

# image tag for kube-vip
kube_vip_tag_version: v0.8.2

# Only enable this if you have set up your own container registry to act as a mirror / pull-through cache
# (harbor / nexus / docker's official registry / etc).
# Can be beneficial for larger dev/test environments (for example if you're getting rate limited by docker hub),
# or air-gapped environments where your nodes don't have internet access after the initial setup
# (which is still needed for downloading the k3s binary and such).
# k3s's documentation about private registries here: https://docs.k3s.io/installation/private-registry
custom_registries: false
# The registries can be authenticated or anonymous, depending on your registry server configuration.
# If they allow anonymous access, simply remove the following bit from custom_registries_yaml
#   configs:
#     "registry.domain.com":
#       auth:
#         username: yourusername
#         password: yourpassword
# The following is an example that pulls all images used in this playbook through your private registries.
# It also allows you to pull your own images from your private registry, without having to use imagePullSecrets
# in your deployments.
# If all you need is your own images and you don't care about caching the docker/quay/ghcr.io images,
# you can just remove those from the mirrors: section.
custom_registries_yaml: |
  mirrors:
    docker.io:
      endpoint:
        - "https://registry.domain.com/v2/dockerhub"
    quay.io:
      endpoint:
        - "https://registry.domain.com/v2/quayio"
    ghcr.io:
      endpoint:
        - "https://registry.domain.com/v2/ghcrio"
    registry.domain.com:
      endpoint:
        - "https://registry.domain.com"

  configs:
    "registry.domain.com":
      auth:
        username: yourusername
        password: yourpassword

# On some distros like Diet Pi, there is no dbus installed. dbus required by the default reboot command.
# Uncomment if you need a custom reboot command
# custom_reboot_command: /usr/sbin/shutdown -r now

# Only enable and configure these if you access the internet through a proxy
# proxy_env:
#   HTTP_PROXY: "http://proxy.domain.local:3128"
#   HTTPS_PROXY: "http://proxy.domain.local:3128"
#   NO_PROXY: "*.domain.local,127.0.0.0/8,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16"

#### HARDENING ####
sysctl_overwrite:
  net.ipv4.ip_forward: 1
  net.ipv6.conf.all.forwarding: 1
  net.ipv6.conf.all.accept_ra: 2

# longhorn_enable: true
# longhorn_values:
#   defaultSettings:
#     allowVolumeCreationWithDegradedAvailability: false
#     defaultReplicaCount: 2
#     defaultDataLocality: best-effort